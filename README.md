# Understanding-Diffusion-Models-as-ResNets

# ðŸ§  Diffusion Models as ResNets

**Author:** Mahesh Godavarti  
**Tagline:** Deep Learning / AI Enthusiast  
**GitHub:** [mahesh-godavarti](https://github.com/mahesh-godavarti)  
**LinkedIn:** [linkedin.com/in/maheshgodavarti](https://www.linkedin.com/in/maheshgodavarti/)

---

## ðŸ“˜ Overview

This project explores how **Diffusion Models** â€” the foundation of modern generative AI â€” can be understood as **deep Residual Networks (ResNets)** performing step-by-step denoising.

The accompanying slide deck and Python scripts provide an intuitive, educational walkthrough of the connection between diffusion processes and residual learning.

---

## ðŸ§© Repository Contents

| File | Description |
|------|--------------|
| `Diffusion_Models_as_ResNets_Redesigned.pptx` | Presentation explaining diffusion models as deep ResNets |
| `mnist_toy_resnet_diffusion.py` | Toy MNIST example illustrating the diffusionâ€“ResNet analogy |
| `generate_step_grids_from_checkpoint.py` | Creates visual grids showing intermediate denoising steps |
| `generate_movie_from_images.py` | Combines saved images into an animation of the diffusion process |

---

## ðŸš€ Key Ideas

- Diffusion models transform random noise into coherent images through **iterative denoising**.  
- Each denoising step can be seen as a **residual update** â€” making diffusion models equivalent to very deep ResNets.  
- The formulation unifies several well-known generative approaches:
  - **DDPM / DDIM:** Noise prediction  
  - **Flow Matching:** Velocity field learning  

> ðŸ§© *Takeaway:* Diffusion = Residual Learning Across Time

---

## ðŸ§ª How to Run the Code

1. **Install dependencies**
   ```bash
   pip install torch torchvision matplotlib numpy
